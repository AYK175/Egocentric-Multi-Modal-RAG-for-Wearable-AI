{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MUNaSqAoYyI0"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os, re\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "    # !pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "else:\n",
    "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
    "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
    "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
    "    !pip install --no-deps unsloth\n",
    "!pip install transformers==4.56.2\n",
    "!pip install --no-deps trl==0.22.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2e76f8fb94844b848cc2ad60b81330d9",
      "31dcce9c6ed34feb85959535f0bcb2d7",
      "0761c59167584b158d43e7eda84d0deb",
      "d020adc1b9b94797a4c52eb4e68d2409",
      "2ffe63c544194c4381957348141bbc71",
      "91cfbe9042be434b83ac121d63ced419",
      "8dee84da64674f9b8eae0ce7c6171ff3",
      "a3a4adfa58d54c8bb1a62c51d05b4a2d",
      "81d802b9786347778c74821aa17b1592",
      "c0f0daba975a4c0f89be23b27079d520",
      "a46dd218585c45b4ac97023492be71ef"
     ]
    },
    "id": "KD2MYMLWbcA7",
    "outputId": "bc27a258-9fa4-4fc6-ce4c-fabf3688c7ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.11.6: Fast Mllama patching. Transformers: 4.56.2.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-80GB. Num GPUs = 1. Max memory: 79.318 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e76f8fb94844b848cc2ad60b81330d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MllamaForConditionalGeneration(\n",
       "  (model): MllamaModel(\n",
       "    (vision_model): MllamaVisionModel(\n",
       "      (patch_embedding): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14), padding=valid, bias=False)\n",
       "      (gated_positional_embedding): MllamaPrecomputedPositionEmbedding(\n",
       "        (tile_embedding): Embedding(9, 8197120)\n",
       "      )\n",
       "      (pre_tile_positional_embedding): MllamaPrecomputedAspectRatioEmbedding(\n",
       "        (embedding): Embedding(9, 5120)\n",
       "      )\n",
       "      (post_tile_positional_embedding): MllamaPrecomputedAspectRatioEmbedding(\n",
       "        (embedding): Embedding(9, 5120)\n",
       "      )\n",
       "      (layernorm_pre): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (layernorm_post): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (transformer): MllamaVisionEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-12): 13 x MllamaVisionEncoderLayer(\n",
       "            (self_attn): MllamaVisionAttention(\n",
       "              (q_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
       "              (k_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
       "              (v_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
       "              (o_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
       "            )\n",
       "            (mlp): MllamaVisionMLP(\n",
       "              (activation_fn): GELUActivation()\n",
       "              (fc1): Linear4bit(in_features=1280, out_features=5120, bias=True)\n",
       "              (fc2): Linear4bit(in_features=5120, out_features=1280, bias=True)\n",
       "            )\n",
       "            (input_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (post_attention_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (13): MllamaVisionEncoderLayer(\n",
       "            (self_attn): MllamaVisionAttention(\n",
       "              (q_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
       "              (k_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
       "              (v_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
       "              (o_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
       "            )\n",
       "            (mlp): MllamaVisionMLP(\n",
       "              (activation_fn): GELUActivation()\n",
       "              (fc1): Linear4bit(in_features=1280, out_features=5120, bias=True)\n",
       "              (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            )\n",
       "            (input_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (post_attention_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (14-31): 18 x MllamaVisionEncoderLayer(\n",
       "            (self_attn): MllamaVisionAttention(\n",
       "              (q_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
       "              (k_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
       "              (v_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
       "              (o_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
       "            )\n",
       "            (mlp): MllamaVisionMLP(\n",
       "              (activation_fn): GELUActivation()\n",
       "              (fc1): Linear4bit(in_features=1280, out_features=5120, bias=True)\n",
       "              (fc2): Linear4bit(in_features=5120, out_features=1280, bias=True)\n",
       "            )\n",
       "            (input_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (post_attention_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (global_transformer): MllamaVisionEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-7): 8 x MllamaVisionEncoderLayer(\n",
       "            (self_attn): MllamaVisionAttention(\n",
       "              (q_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
       "              (k_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
       "              (v_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
       "              (o_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
       "            )\n",
       "            (mlp): MllamaVisionMLP(\n",
       "              (activation_fn): GELUActivation()\n",
       "              (fc1): Linear4bit(in_features=1280, out_features=5120, bias=True)\n",
       "              (fc2): Linear4bit(in_features=5120, out_features=1280, bias=True)\n",
       "            )\n",
       "            (input_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (post_attention_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (language_model): MllamaTextModel(\n",
       "      (embed_tokens): Embedding(128264, 4096, padding_idx=128004)\n",
       "      (layers): ModuleList(\n",
       "        (0): MllamaSelfAttentionDecoderLayer(\n",
       "          (self_attn): MllamaTextSelfAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "        (1): MllamaSelfAttentionDecoderLayer(\n",
       "          (self_attn): MllamaTextSelfAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "        (2): MllamaSelfAttentionDecoderLayer(\n",
       "          (self_attn): MllamaTextSelfAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "        (3): MllamaCrossAttentionDecoderLayer(\n",
       "          (cross_attn): MllamaTextCrossAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n",
       "            (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "        (4-7): 4 x MllamaSelfAttentionDecoderLayer(\n",
       "          (self_attn): MllamaTextSelfAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "        (8): MllamaCrossAttentionDecoderLayer(\n",
       "          (cross_attn): MllamaTextCrossAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n",
       "            (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "        (9-12): 4 x MllamaSelfAttentionDecoderLayer(\n",
       "          (self_attn): MllamaTextSelfAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "        (13): MllamaCrossAttentionDecoderLayer(\n",
       "          (cross_attn): MllamaTextCrossAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n",
       "            (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "        (14-17): 4 x MllamaSelfAttentionDecoderLayer(\n",
       "          (self_attn): MllamaTextSelfAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "        (18): MllamaCrossAttentionDecoderLayer(\n",
       "          (cross_attn): MllamaTextCrossAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n",
       "            (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "        (19-22): 4 x MllamaSelfAttentionDecoderLayer(\n",
       "          (self_attn): MllamaTextSelfAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "        (23): MllamaCrossAttentionDecoderLayer(\n",
       "          (cross_attn): MllamaTextCrossAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n",
       "            (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "        (24-27): 4 x MllamaSelfAttentionDecoderLayer(\n",
       "          (self_attn): MllamaTextSelfAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "        (28): MllamaCrossAttentionDecoderLayer(\n",
       "          (cross_attn): MllamaTextCrossAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n",
       "            (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "        (29-32): 4 x MllamaSelfAttentionDecoderLayer(\n",
       "          (self_attn): MllamaTextSelfAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "        (33): MllamaCrossAttentionDecoderLayer(\n",
       "          (cross_attn): MllamaTextCrossAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n",
       "            (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "        (34-37): 4 x MllamaSelfAttentionDecoderLayer(\n",
       "          (self_attn): MllamaTextSelfAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "        (38): MllamaCrossAttentionDecoderLayer(\n",
       "          (cross_attn): MllamaTextCrossAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (q_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n",
       "            (k_norm): MllamaTextRMSNorm((128,), eps=1e-05)\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "        (39): MllamaSelfAttentionDecoderLayer(\n",
       "          (self_attn): MllamaTextSelfAttention(\n",
       "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (mlp): MllamaTextMLP(\n",
       "            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): MllamaTextRMSNorm((4096,), eps=1e-05)\n",
       "      (rotary_emb): MllamaRotaryEmbedding()\n",
       "    )\n",
       "    (multi_modal_projector): Linear(in_features=7680, out_features=4096, bias=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from unsloth import FastVisionModel\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "model, processor = FastVisionModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-11B-Vision-Instruct\",\n",
    "    load_in_4bit = True,\n",
    ")\n",
    "FastVisionModel.for_inference(model)\n",
    "# The model all the padding on the left side so we can extract the last token for sentence summary.\n",
    "processor.tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "bc0e1c9d257848eab7085646c4f1d237",
      "65f66643593a4c00a7a8117b8033df58",
      "f31c268e1ede4d679b8bed54865c7a91",
      "9b78bc7d0ee8454d83746c1c0edd51d8",
      "8f492c7586b44f17aa5c496e615818c5",
      "d5e6e85d1e02498fba025901d2b58268",
      "d267b3b4a9eb4dfb896277b6c2c121bf",
      "0ca04d55466c41c6a34d31d987e9849a",
      "b77bc25273d34463ad7c2ce2de3a70bc",
      "33874db08fb24c9ca578b153546b1dca",
      "e0b87686659c44b794bb50d33e4b6457",
      "d4b1e1bdd3ee42b3afaaf822456773f0",
      "9162d247edb4457d8d931cb6e428e47f",
      "434650a45f434643a01bc1af710d6ff0",
      "393835a50e5745a7873fcaf1a3a26d92",
      "d6e9a13ca58245f7af3db4c76d0dd338",
      "f5f33ce3ea634f59bf7b1281dee125d5",
      "2ab276d85e314a3ea954ea3e6f285a7c",
      "b31355a2a91640be90bef5aab4452d92",
      "39bbf2c7e80f435da8c8ba17776b79ac",
      "f9b62695c607418ab04f280edf58d517",
      "2853e4a5764549549fcd99e9d7c05bbc"
     ]
    },
    "id": "4eO5msfhbjWI",
    "outputId": "16daaffd-d566-46c7-cdbe-016bee5290fb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0e1c9d257848eab7085646c4f1d237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1938 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b1e1bdd3ee42b3afaaf822456773f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating public_test split:   0%|          | 0/1936 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"crag-mm-2025/crag-mm-single-turn-public\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBhXQ7KpjEaW"
   },
   "source": [
    "### **ELIP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "2afbe1b8d5e34566bc76b1da3cc0eb35",
      "ec8e8538bc304a4c809a99152a7c33de",
      "f80f8177761545498e14be9089573c1e",
      "44695cb025494a9eae821496f7922918",
      "61f55f6605ed4961a953b6a361d0c446",
      "81768379c8034296ac21cb049f7ee5f2",
      "e4be8b2a035d43119bef38694dc6ccac",
      "064137bb5bd54f85a19d48094e8b134f",
      "6d0a666089ca4e89b391e465e360985d",
      "2ce3a8898f1448c8a6e08e0c31ec4df6",
      "b3a95d21e17148f7a7411eed5ed10ef8"
     ]
    },
    "id": "rSOJe-hgbxtI",
    "outputId": "c5036180-4e1a-4a49-e416-92d9ed26b4cd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afbe1b8d5e34566bc76b1da3cc0eb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1938 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# A. Create a simple Dataset Wrapper\n",
    "class LlamaAlignmentDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, processor):\n",
    "        self.data = hf_dataset\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        image = item['image']\n",
    "        prompt = item['turns']['query'][0]\n",
    "        answer = item['answers']['ans_full'][0]\n",
    "\n",
    "        return image, prompt, answer\n",
    "\n",
    "valid_data = dataset['validation'].filter(lambda x: x['image'] is not None)\n",
    "\n",
    "# pin_memory=True: Speeds up transfer to GPU\n",
    "train_ds = LlamaAlignmentDataset(valid_data, processor)\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=lambda x: x[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "S5msG42hU5V1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TextToVisionBridge(nn.Module):\n",
    "    def __init__(self, base_model, num_extra_patches=10):\n",
    "        super().__init__()\n",
    "        self.model = base_model\n",
    "        self.vision_model = base_model.vision_model\n",
    "        self.language_model = base_model.language_model\n",
    "\n",
    "        # Dynamically get device/dtype\n",
    "        param = next(base_model.parameters())\n",
    "        self.device = param.device\n",
    "        self.dtype = param.dtype\n",
    "\n",
    "        # --- Linear Bridge ---\n",
    "        # Maps Text Dim (4096) -> Vision Dim (1280)\n",
    "        self.text_to_patch = nn.Sequential(\n",
    "            nn.Linear(4096, 5376),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(5376, 6656),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(6656, 9216),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(9216, num_extra_patches * 1280)\n",
    "        ).to(self.device, dtype=self.dtype)\n",
    "\n",
    "        self.num_extra_patches = num_extra_patches\n",
    "\n",
    "        # Freeze everything\n",
    "        for p in self.vision_model.parameters(): p.requires_grad = False\n",
    "        for p in self.language_model.parameters(): p.requires_grad = False\n",
    "\n",
    "        # Unfreeze Bridge\n",
    "        for p in self.text_to_patch.parameters(): p.requires_grad = True\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: torch.Tensor,\n",
    "        input_ids: torch.Tensor = None,\n",
    "        attention_mask: torch.Tensor = None,\n",
    "        aspect_ratio_ids: torch.Tensor = None,\n",
    "        **kwargs,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        # Unpack and Flatten Images\n",
    "        if pixel_values.dim() == 6:\n",
    "            B, _, num_tiles, C, H, W = pixel_values.shape\n",
    "        else:\n",
    "            B, num_tiles, C, H, W = pixel_values.shape\n",
    "\n",
    "        # Flatten Batch and Tiles together -> [B*Tiles, C, H, W]\n",
    "        imgs = pixel_values.reshape(B * num_tiles, C, H, W)\n",
    "\n",
    "        # 2. Get Text Summaries\n",
    "        with torch.no_grad():\n",
    "            text_emb = self.language_model.embed_tokens(input_ids)\n",
    "\n",
    "        # Take last token state since it is decoder only model\n",
    "        # [Batch_Size, Sequence_Length, Hidden_Dimension] -> [B, 4096]\n",
    "        text_summary = text_emb[:, -1, :]\n",
    "\n",
    "        # 3. Generate Extra Patches\n",
    "        # Map to Vision Dim -> [B, Num_Patches, 1280]\n",
    "        extra_patches = self.text_to_patch(text_summary).view(B, self.num_extra_patches, 1280)\n",
    "\n",
    "        # Need [B * Tiles, Num_Patches, 1280]\n",
    "        # [B, 1, N, D]\n",
    "        extra_patches = extra_patches.unsqueeze(1)\n",
    "\n",
    "        # Repeat for every tile -> [B, Tiles, N, D]\n",
    "        # Duplicate the patches for every tile.\n",
    "        extra_patches = extra_patches.repeat(1, num_tiles, 1, 1)\n",
    "\n",
    "        # FLATTEN Batch and Tiles -> [B*Tiles, N, D]\n",
    "        extra_patches = extra_patches.reshape(1, B * num_tiles, self.num_extra_patches, 1280)\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Convert raw pixels into patch embeddings\n",
    "            x = self.vision_model.patch_embedding(imgs)\n",
    "\n",
    "            # Flatten spatial dims (H*W) into Sequence length and transpose.\n",
    "            # [Batch*Tiles, Seq_Len, 1280]\n",
    "            x = x.flatten(2).transpose(1, 2)\n",
    "\n",
    "            # Create a Learnable Class Token (CLS) initialized to zeros.\n",
    "            cls_token = torch.zeros(x.shape[0], 1, x.shape[-1], device=x.device, dtype=x.dtype)\n",
    "\n",
    "            # Append the CLS token to the sequence.\n",
    "            x = torch.cat([cls_token, x], dim=1)\n",
    "\n",
    "            # Apply Llama 3.2's special gated positional embeddings based on tile ID.\n",
    "            x = self.vision_model.gated_positional_embedding(x, aspect_ratio_ids)\n",
    "\n",
    "            # Apply Layer Normalization before the Transformer layers.\n",
    "            x = self.vision_model.layernorm_pre(x)\n",
    "\n",
    "        # Concat the extra patches\n",
    "        x = torch.cat([extra_patches, x], dim=2)\n",
    "        x = x.flatten(0, 1)\n",
    "\n",
    "\n",
    "        # Run the Transformer Encoder Layers.\n",
    "        x = self.vision_model.transformer(x)\n",
    "        # Save all hidden states (used later for multi-stage feature aggregation).\n",
    "        all_intermediate_hidden_states = x[1]\n",
    "        x = x[0]\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = self.vision_model.layernorm_post(x)\n",
    "\n",
    "        # Project vision features to language model dimension.\n",
    "        vision_output = self.vision_model.global_transformer(x)\n",
    "\n",
    "        # Get the indices of layers to extract features from (defined in model config). Llama extract special part of layer\n",
    "        indices = self.model.config.vision_config.intermediate_layers_indices\n",
    "\n",
    "        # Stack all layer outputs into one tensor.\n",
    "        intermediate_hidden_states = torch.stack(all_intermediate_hidden_states, dim=-1)\n",
    "\n",
    "        # Select only the specific layers required by the configuration.\n",
    "        intermediate_hidden_states = intermediate_hidden_states[..., indices]\n",
    "\n",
    "        # Combine intermediate features with the final vision output.\n",
    "        output = torch.cat([intermediate_hidden_states, vision_output.last_hidden_state.unsqueeze(-1)], dim=-1)\n",
    "\n",
    "        output = output.flatten(2)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qrNPFSMIU0de",
    "outputId": "96d668e1-c18f-486d-842c-b4f4d9278ec0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 8/1423 [00:07<13:19,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 7 | Loss: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 16/1423 [00:10<10:39,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 15 | Loss: 0.9883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 24/1423 [00:14<10:24,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 23 | Loss: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 32/1423 [00:17<10:17,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 31 | Loss: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 40/1423 [00:21<10:07,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 39 | Loss: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 48/1423 [00:24<10:09,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 47 | Loss: 0.9805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 56/1423 [00:28<10:18,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 55 | Loss: 0.9805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 64/1423 [00:31<10:01,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 63 | Loss: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▌         | 72/1423 [00:35<10:07,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 71 | Loss: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6%|▌         | 80/1423 [00:38<10:10,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 79 | Loss: 0.9766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6%|▌         | 88/1423 [00:42<09:54,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 87 | Loss: 0.9805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   7%|▋         | 96/1423 [00:45<09:47,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 95 | Loss: 0.9766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   7%|▋         | 104/1423 [00:49<09:42,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 103 | Loss: 0.9766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8%|▊         | 112/1423 [00:52<09:43,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 111 | Loss: 0.9805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8%|▊         | 120/1423 [00:56<09:40,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 119 | Loss: 0.9766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   9%|▉         | 128/1423 [00:59<09:29,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 127 | Loss: 0.9727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|▉         | 136/1423 [01:02<09:34,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 135 | Loss: 0.9727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|█         | 144/1423 [01:06<09:30,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 143 | Loss: 0.9727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11%|█         | 152/1423 [01:09<09:35,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 151 | Loss: 0.9648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11%|█         | 160/1423 [01:13<09:19,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 159 | Loss: 0.9727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  12%|█▏        | 168/1423 [01:16<09:44,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 167 | Loss: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  12%|█▏        | 176/1423 [01:20<09:16,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 175 | Loss: 0.9648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  13%|█▎        | 184/1423 [01:23<09:10,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 183 | Loss: 0.9648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  13%|█▎        | 192/1423 [01:27<09:09,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 191 | Loss: 0.9609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  14%|█▍        | 200/1423 [01:30<09:02,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 199 | Loss: 0.9648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  15%|█▍        | 208/1423 [01:34<08:58,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 207 | Loss: 0.9648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  15%|█▌        | 216/1423 [01:37<08:53,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 215 | Loss: 0.9609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  16%|█▌        | 224/1423 [01:41<08:51,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 223 | Loss: 0.9609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  16%|█▋        | 232/1423 [01:44<08:46,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 231 | Loss: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  17%|█▋        | 240/1423 [01:48<08:45,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 239 | Loss: 0.9609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  17%|█▋        | 248/1423 [01:51<08:37,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 247 | Loss: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  18%|█▊        | 256/1423 [01:55<08:36,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 255 | Loss: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  19%|█▊        | 264/1423 [01:58<08:28,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 263 | Loss: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  19%|█▉        | 272/1423 [02:01<08:28,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 271 | Loss: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  20%|█▉        | 280/1423 [02:05<08:27,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 279 | Loss: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  20%|██        | 288/1423 [02:08<08:22,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 287 | Loss: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  21%|██        | 296/1423 [02:12<08:17,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 295 | Loss: 0.9609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  21%|██▏       | 304/1423 [02:15<08:25,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 303 | Loss: 0.9531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  22%|██▏       | 312/1423 [02:19<08:27,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 311 | Loss: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  22%|██▏       | 320/1423 [02:22<08:19,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 319 | Loss: 0.9492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  23%|██▎       | 328/1423 [02:26<08:09,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 327 | Loss: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  24%|██▎       | 336/1423 [02:29<07:59,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 335 | Loss: 0.9492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  24%|██▍       | 344/1423 [02:33<07:58,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 343 | Loss: 0.9609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  25%|██▍       | 352/1423 [02:36<07:54,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 351 | Loss: 0.9492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  25%|██▌       | 360/1423 [02:40<07:51,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 359 | Loss: 0.9492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  26%|██▌       | 368/1423 [02:43<07:46,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 367 | Loss: 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  26%|██▋       | 376/1423 [02:47<07:43,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 375 | Loss: 0.9492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  27%|██▋       | 384/1423 [02:50<07:35,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 383 | Loss: 0.9492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  28%|██▊       | 392/1423 [02:53<07:35,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 391 | Loss: 0.9648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  28%|██▊       | 400/1423 [02:57<07:29,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 399 | Loss: 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  29%|██▊       | 408/1423 [03:00<07:27,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 407 | Loss: 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  29%|██▉       | 416/1423 [03:04<07:23,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 415 | Loss: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  30%|██▉       | 424/1423 [03:07<07:28,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 423 | Loss: 0.9492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  30%|███       | 432/1423 [03:11<07:17,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 431 | Loss: 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  31%|███       | 440/1423 [03:14<07:10,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 439 | Loss: 0.9492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  31%|███▏      | 448/1423 [03:18<07:08,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 447 | Loss: 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  32%|███▏      | 456/1423 [03:21<07:06,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 455 | Loss: 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  33%|███▎      | 464/1423 [03:24<07:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 463 | Loss: 0.9492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  33%|███▎      | 472/1423 [03:28<06:55,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 471 | Loss: 0.9492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  34%|███▎      | 480/1423 [03:31<06:56,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 479 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  34%|███▍      | 488/1423 [03:35<06:51,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 487 | Loss: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  35%|███▍      | 496/1423 [03:38<06:50,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 495 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  35%|███▌      | 504/1423 [03:42<06:45,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 503 | Loss: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  36%|███▌      | 512/1423 [03:45<06:52,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 511 | Loss: 0.9492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  37%|███▋      | 520/1423 [03:49<06:44,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 519 | Loss: 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  37%|███▋      | 528/1423 [03:52<06:41,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 527 | Loss: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  38%|███▊      | 536/1423 [03:56<06:36,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 535 | Loss: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  38%|███▊      | 544/1423 [03:59<06:37,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 543 | Loss: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  39%|███▉      | 552/1423 [04:03<06:27,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 551 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  39%|███▉      | 560/1423 [04:06<06:24,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 559 | Loss: 0.9492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  40%|███▉      | 568/1423 [04:11<06:47,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 567 | Loss: 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  40%|████      | 576/1423 [04:14<06:22,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 575 | Loss: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  41%|████      | 584/1423 [04:19<06:54,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 583 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  42%|████▏     | 592/1423 [04:22<06:18,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 591 | Loss: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  42%|████▏     | 600/1423 [04:26<06:02,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 599 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  43%|████▎     | 608/1423 [04:29<05:58,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 607 | Loss: 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  43%|████▎     | 616/1423 [04:32<05:53,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 615 | Loss: 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  44%|████▍     | 624/1423 [04:37<06:18,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 623 | Loss: 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  44%|████▍     | 632/1423 [04:40<05:48,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 631 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  45%|████▍     | 640/1423 [04:44<05:45,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 639 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  46%|████▌     | 648/1423 [04:48<06:08,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 647 | Loss: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  46%|████▌     | 656/1423 [04:51<05:43,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 655 | Loss: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  47%|████▋     | 664/1423 [04:55<05:36,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 663 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  47%|████▋     | 672/1423 [04:58<05:33,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 671 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  48%|████▊     | 680/1423 [05:02<05:31,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 679 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  48%|████▊     | 688/1423 [05:05<05:23,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 687 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  49%|████▉     | 696/1423 [05:09<05:20,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 695 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  49%|████▉     | 704/1423 [05:12<05:17,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 703 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|█████     | 712/1423 [05:16<05:18,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 711 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  51%|█████     | 720/1423 [05:19<05:10,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 719 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  51%|█████     | 728/1423 [05:22<05:08,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 727 | Loss: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  52%|█████▏    | 736/1423 [05:26<05:04,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 735 | Loss: 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  52%|█████▏    | 744/1423 [05:29<04:58,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 743 | Loss: 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  53%|█████▎    | 752/1423 [05:33<04:55,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 751 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  53%|█████▎    | 760/1423 [05:36<04:53,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 759 | Loss: 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  54%|█████▍    | 768/1423 [05:40<04:50,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 767 | Loss: 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  55%|█████▍    | 776/1423 [05:43<04:43,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 775 | Loss: 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  55%|█████▌    | 784/1423 [05:47<04:43,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 783 | Loss: 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  56%|█████▌    | 792/1423 [05:50<04:40,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 791 | Loss: 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  56%|█████▌    | 800/1423 [05:54<04:39,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 799 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  57%|█████▋    | 808/1423 [05:57<04:30,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 807 | Loss: 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  57%|█████▋    | 816/1423 [06:00<04:26,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 815 | Loss: 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  58%|█████▊    | 824/1423 [06:04<04:29,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 823 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  58%|█████▊    | 832/1423 [06:07<04:22,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 831 | Loss: 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  59%|█████▉    | 840/1423 [06:11<04:17,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 839 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  60%|█████▉    | 848/1423 [06:14<04:15,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 847 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  60%|██████    | 856/1423 [06:18<04:16,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 855 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  61%|██████    | 864/1423 [06:21<04:06,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 863 | Loss: 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  61%|██████▏   | 872/1423 [06:25<04:03,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 871 | Loss: 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  62%|██████▏   | 880/1423 [06:28<04:02,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 879 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  62%|██████▏   | 888/1423 [06:32<03:55,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 887 | Loss: 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  63%|██████▎   | 896/1423 [06:35<03:52,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 895 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  64%|██████▎   | 904/1423 [06:39<03:52,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 903 | Loss: 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  64%|██████▍   | 912/1423 [06:42<03:44,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 911 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  65%|██████▍   | 920/1423 [06:46<03:40,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 919 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  65%|██████▌   | 928/1423 [06:49<03:37,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 927 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  66%|██████▌   | 936/1423 [06:52<03:37,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 935 | Loss: 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  66%|██████▋   | 944/1423 [06:56<03:33,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 943 | Loss: 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  67%|██████▋   | 952/1423 [06:59<03:26,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 951 | Loss: 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  67%|██████▋   | 960/1423 [07:03<03:24,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 959 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  68%|██████▊   | 968/1423 [07:06<03:22,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 967 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  69%|██████▊   | 976/1423 [07:10<03:16,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 975 | Loss: 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  69%|██████▉   | 984/1423 [07:13<03:15,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 983 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  70%|██████▉   | 992/1423 [07:17<03:12,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 991 | Loss: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  70%|███████   | 1000/1423 [07:20<03:06,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 999 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  71%|███████   | 1008/1423 [07:24<03:03,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1007 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  71%|███████▏  | 1016/1423 [07:27<02:58,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1015 | Loss: 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  72%|███████▏  | 1024/1423 [07:30<02:57,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1023 | Loss: 0.9180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  73%|███████▎  | 1032/1423 [07:34<02:52,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1031 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  73%|███████▎  | 1040/1423 [07:37<02:50,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1039 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  74%|███████▎  | 1048/1423 [07:41<02:47,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1047 | Loss: 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  74%|███████▍  | 1056/1423 [07:44<02:43,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1055 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  75%|███████▍  | 1064/1423 [07:48<02:36,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1063 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  75%|███████▌  | 1072/1423 [07:51<02:35,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1071 | Loss: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  76%|███████▌  | 1080/1423 [07:55<02:31,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1079 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  76%|███████▋  | 1088/1423 [07:58<02:27,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1087 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  77%|███████▋  | 1096/1423 [08:02<02:24,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1095 | Loss: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  78%|███████▊  | 1104/1423 [08:05<02:21,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1103 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  78%|███████▊  | 1112/1423 [08:08<02:18,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1111 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  79%|███████▊  | 1120/1423 [08:12<02:13,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1119 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  79%|███████▉  | 1128/1423 [08:15<02:10,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1127 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  80%|███████▉  | 1136/1423 [08:19<02:09,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1135 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  80%|████████  | 1144/1423 [08:22<02:03,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1143 | Loss: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  81%|████████  | 1152/1423 [08:26<01:59,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1151 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  82%|████████▏ | 1160/1423 [08:29<01:56,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1159 | Loss: 0.9180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  82%|████████▏ | 1168/1423 [08:33<01:52,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1167 | Loss: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  83%|████████▎ | 1176/1423 [08:36<01:48,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1175 | Loss: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  83%|████████▎ | 1184/1423 [08:39<01:45,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1183 | Loss: 0.9180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  84%|████████▍ | 1192/1423 [08:43<01:41,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1191 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  84%|████████▍ | 1200/1423 [08:46<01:37,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1199 | Loss: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  85%|████████▍ | 1208/1423 [08:50<01:34,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1207 | Loss: 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  85%|████████▌ | 1216/1423 [08:53<01:31,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1215 | Loss: 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  86%|████████▌ | 1224/1423 [08:57<01:29,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1223 | Loss: 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  87%|████████▋ | 1232/1423 [09:00<01:25,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1231 | Loss: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  87%|████████▋ | 1240/1423 [09:04<01:20,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1239 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  88%|████████▊ | 1248/1423 [09:07<01:17,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1247 | Loss: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  88%|████████▊ | 1256/1423 [09:10<01:14,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1255 | Loss: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  89%|████████▉ | 1264/1423 [09:15<01:20,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1263 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  89%|████████▉ | 1272/1423 [09:18<01:07,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1271 | Loss: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  90%|████████▉ | 1280/1423 [09:22<01:04,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1279 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  91%|█████████ | 1288/1423 [09:25<00:59,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1287 | Loss: 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  91%|█████████ | 1296/1423 [09:29<00:55,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1295 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  92%|█████████▏| 1304/1423 [09:32<00:52,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1303 | Loss: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  92%|█████████▏| 1312/1423 [09:35<00:48,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1311 | Loss: 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  93%|█████████▎| 1320/1423 [09:39<00:45,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1319 | Loss: 0.9141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  93%|█████████▎| 1328/1423 [09:42<00:41,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1327 | Loss: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  94%|█████████▍| 1336/1423 [09:46<00:38,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1335 | Loss: 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  94%|█████████▍| 1344/1423 [09:49<00:34,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1343 | Loss: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  95%|█████████▌| 1352/1423 [09:53<00:31,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1351 | Loss: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  96%|█████████▌| 1360/1423 [09:56<00:27,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1359 | Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  96%|█████████▌| 1368/1423 [10:00<00:24,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1367 | Loss: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  97%|█████████▋| 1376/1423 [10:03<00:21,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1375 | Loss: 0.9180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  97%|█████████▋| 1384/1423 [10:06<00:17,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1383 | Loss: 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  98%|█████████▊| 1392/1423 [10:10<00:13,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1391 | Loss: 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  98%|█████████▊| 1400/1423 [10:13<00:10,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1399 | Loss: 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  99%|█████████▉| 1408/1423 [10:17<00:06,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1407 | Loss: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████▉| 1416/1423 [10:20<00:03,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 1415 | Loss: 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1423/1423 [10:24<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def get_text_embedding(model, processor, text_list, device):\n",
    "    \"\"\"\n",
    "    Encodes the 'Answer' text into a single vector using the LLM's embedding layer.\n",
    "    We extract the last token embedding.\n",
    "    \"\"\"\n",
    "    inputs = processor.tokenizer(\n",
    "        text_list, return_tensors=\"pt\", padding=True, truncation=True\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embeddings = model.language_model.embed_tokens(inputs[\"input_ids\"])\n",
    "\n",
    "        # Extract the last token embedding\n",
    "        last_embedding = embeddings[:, -1, :]\n",
    "\n",
    "    return last_embedding\n",
    "\n",
    "print(\"Starting Training...\")\n",
    "BATCH_SIZE = 1\n",
    "GRAD_ACCUMULATION = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 1\n",
    "NUM_EXTRA_PATCHES = 10\n",
    "\n",
    "bridge_model = TextToVisionBridge(model).to(model.device)\n",
    "bridge_model.text_to_patch.train()\n",
    "bridge_model.text_to_patch.to(torch.bfloat16)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(bridge_model.text_to_patch.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=50\n",
    ")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "\n",
    "    for step, (image, prompt, answer) in enumerate(train_pbar):\n",
    "\n",
    "        prompt_text = f\"{prompt} <|end_of_text|>\"\n",
    "        text_inputs = processor.tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "\n",
    "        image_inputs = processor(images=image, return_tensors=\"pt\")\n",
    "        image_inputs = {k: v.to(model.device) for k, v in image_inputs.items()}\n",
    "\n",
    "        if \"pixel_values\" in image_inputs:\n",
    "            image_inputs[\"pixel_values\"] = image_inputs[\"pixel_values\"].to(torch.bfloat16)\n",
    "\n",
    "        # Output shape: [B, Seq_Len, Vision_Dim]\n",
    "        vision_outputs = bridge_model(\n",
    "            pixel_values=image_inputs[\"pixel_values\"],\n",
    "            input_ids=text_inputs[\"input_ids\"],\n",
    "            aspect_ratio_ids=image_inputs.get(\"aspect_ratio_ids\", None)\n",
    "        )\n",
    "\n",
    "        # Project to llm space\n",
    "        projected_vision = model.model.multi_modal_projector(vision_outputs)\n",
    "\n",
    "        # takes every single vision patch\n",
    "        # Treat every vision patch as an independent embedding. Row is patches column is embedding dimension\n",
    "        vision_vec = projected_vision.view(-1, 4096)\n",
    "\n",
    "        target_vec = get_text_embedding(model, processor, [prompt_text], model.device)\n",
    "\n",
    "        v_norm = F.normalize(vision_vec, p=2, dim=1)\n",
    "        t_norm = F.normalize(target_vec, p=2, dim=1)\n",
    "\n",
    "        similarity_map = torch.matmul(v_norm, t_norm.t()).squeeze()\n",
    "\n",
    "        k = 1500\n",
    "\n",
    "        # Find the scores of the best K patches\n",
    "        # Instead of getting one patch or whole image mean we extract a region of patch and calculate it mean.\n",
    "        # So it more like letting the model have a higher score when they pay more attention of the object text mention\n",
    "        top_k_scores, top_k_indices = torch.topk(similarity_map, k)\n",
    "\n",
    "        loss = 1 - top_k_scores.mean()\n",
    "\n",
    "        # Backward\n",
    "        loss = loss / GRAD_ACCUMULATION\n",
    "        loss.backward()\n",
    "\n",
    "        if (step + 1) % GRAD_ACCUMULATION == 0:\n",
    "          optimizer.step()\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          # Update Scheduler based on current loss\n",
    "          current_loss_val = loss.item() * GRAD_ACCUMULATION\n",
    "          scheduler.step(current_loss_val)\n",
    "\n",
    "          print(f\"Epoch {epoch} | Step {step} | Loss: {current_loss_val:.4f}\")\n",
    "\n",
    "print(\"Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_s_ahbzcjs2",
    "outputId": "60c66c35-cf4d-4367-ecdd-592a390ccd94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating...\n",
      "The vehicle's model is a 1969-1970 Chevrolet Camaro, and the engine is a 350. The 1969-1970 Chevrolet Camaro with a 350 engine has a top speed of approximately 120 mph. The 1969-1970 Chevrolet Camaro with a 350 engine has a top speed of approximately 120 mph. The 1969-1970 Chevrolet Camaro with a 350 engine has a top speed of approximately 120 mph. The 1969-1970 Chevrolet Camaro with a 350 engine has a top speed of approximately 120 mph. The 1969-1970 Chevrolet Camaro with a 350 engine has a top speed of approximately 120 mph. The"
     ]
    }
   ],
   "source": [
    "example = dataset['public_test'][0]\n",
    "image = example['image']\n",
    "prompt = example['turns']['query'][0]\n",
    "\n",
    "bridge_model.eval()\n",
    "inputs = processor(image, prompt, return_tensors=\"pt\").to(model.device)\n",
    "inputs = {\n",
    "    k: (v.to(torch.bfloat16) if torch.is_floating_point(v) else v)\n",
    "    for k, v in inputs.items()\n",
    "}\n",
    "\n",
    "out = bridge_model(**inputs)\n",
    "result = model.model.multi_modal_projector(out)\n",
    "\n",
    "batch_size = 1\n",
    "num_images = 1\n",
    "num_tiles = 4\n",
    "\n",
    "# Reshape: [4, 1611, 4096] -> [1, 1, 4, 1611, 4096]\n",
    "cross_attention_states = result.view(batch_size, num_images, num_tiles, 1611, 4096)\n",
    "\n",
    "cross_attention_mask = torch.ones(\n",
    "    (batch_size, num_images, num_tiles, 1611),\n",
    "    dtype=torch.bfloat16,\n",
    "    device=result.device\n",
    ")\n",
    "cross_attention_mask = cross_attention_mask.view(batch_size, 1, 1, -1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.language_model(\n",
    "    input_ids=inputs['input_ids'],\n",
    "    attention_mask=inputs['attention_mask'],\n",
    "    cross_attention_states=cross_attention_states,\n",
    "    cross_attention_mask=cross_attention_mask\n",
    ")\n",
    "\n",
    "\n",
    "input_ids = inputs['input_ids']\n",
    "generated_text = \"\"\n",
    "\n",
    "print(\"Generating...\")\n",
    "\n",
    "for i in range(150):\n",
    "    outputs = model.language_model(\n",
    "        input_ids=input_ids,\n",
    "        cross_attention_states=cross_attention_states,\n",
    "        cross_attention_mask=cross_attention_mask\n",
    "    )\n",
    "\n",
    "    logits = model.lm_head(outputs.last_hidden_state)\n",
    "\n",
    "    # Get the next token ID\n",
    "    next_token_logits = logits[:, -1, :]\n",
    "    next_token_id = torch.argmax(next_token_logits, dim=-1).unsqueeze(-1)\n",
    "\n",
    "    # 4. Check for EOS (End of Sentence)\n",
    "    if next_token_id.item() == processor.tokenizer.eos_token_id:\n",
    "        print(\"\\n<EOS reached>\")\n",
    "        break\n",
    "\n",
    "    input_ids = torch.cat([input_ids, next_token_id], dim=1)\n",
    "\n",
    "    # Decode and print\n",
    "    word = processor.tokenizer.decode(next_token_id[0])\n",
    "    generated_text += word\n",
    "    print(word, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
